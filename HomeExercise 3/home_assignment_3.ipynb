{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 3\n",
    "\n",
    "You should work on the assignement in groups of 2 participants. \n",
    "\n",
    "Upload your solution as a jupyter notebook to L2P by 17th of July 23:59h. (The deadline is strict)\n",
    "\n",
    "Do not forget to specify the names of all contributing students in the jupyter notebook.\n",
    "\n",
    "You should add comments to your code where necessary and print the relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team\n",
    "Deniz Schmidt 334744,\n",
    "Dinc Erduran 262999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network representation\n",
    "Given a network obtain representations for the nodes in the jazz network (you can download it from 'http://konect.uni-koblenz.de/networks/arenas-jazz'). The representations are to be obtained the following way. \n",
    "\n",
    "1. Let $Z_u$ and $Z_v$ are the representations of nodes $u$ and $v$. At each step of stochastic gradient descent (SGD) you should randomly select a pair of nodes and minimize the loss function - \n",
    "\n",
    "   $(Z_u^T Z_v - A_{u,v})^2$\n",
    "   \n",
    "2. Obtain another representation of the nodes in the network using the same procedure as in 1 but this time with the loss function as - \n",
    "\n",
    "   $(Z_u^T Z_v - A_{u,v})^2 + (Z_u^T Z_v - A_{u,v}^2)^2$\n",
    "   \n",
    "3. From these two representations obtain the 5-nearest neighbors of node '0'. The distance between two nodes can be measured as the euclidean distance between the representations of the two nodes.\n",
    "\n",
    "\n",
    "  \n",
    "Hints: Calculate the gradient for the loss function and update the representaion vectors using SGD. You can keep the learning rate as 0.001 and the number of iterations as 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random as r\n",
    "import math\n",
    "\n",
    "#loss functions\n",
    "#args: node u>0, node v>0, representation matrix, adjacency matrix\n",
    "def loss1(u, v, emMat, adMat):\n",
    "    tmp = np.matmul(emMat[:,u-1].T, emMat[:,v-1]).item(0,0) - adMat.item(u-1,v-1)\n",
    "    return tmp**2\n",
    "\n",
    "def loss2(u, v, emMat, adMat):\n",
    "    tmp1 = np.matmul(emMat[:,u-1].T, emMat[:,v-1]).item(0,0) - adMat.item(u-1,v-1)\n",
    "    tmp2 = np.matmul(emMat[:,u-1].T, emMat[:,v-1]).item(0,0) - np.matmul(adMat,adMat).item(u-1,v-1)\n",
    "    return tmp1**2 + tmp2**2\n",
    "\n",
    "#get data from file\n",
    "fs = open('out.arenas-jazz')\n",
    "G = nx.Graph()\n",
    "for line in fs:\n",
    "    if re.match(\"%.*\",line):\n",
    "        continue\n",
    "    else:\n",
    "        u,v = line.strip().split()\n",
    "        G.add_edge(u,v)\n",
    "\n",
    "#get adjacency matrix\n",
    "adMat = nx.adjacency_matrix(G).todense().astype(float)\n",
    "rows = adMat.shape[0]\n",
    "cols = adMat.shape[1]\n",
    "\n",
    "#use probabilistic adjacency matrix because standard one results in too large numbers to compute\n",
    "if True:\n",
    "    i = 0\n",
    "    while i < rows:\n",
    "        s = adMat[i,:].sum()\n",
    "        j = 0\n",
    "        while j < cols:\n",
    "            adMat[i,j] /= s\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "#create initial embedding matrix as copy of adjacency matrix\n",
    "emMat = adMat.copy()\n",
    "\n",
    "#do gradient descent\n",
    "learnRate = 0.001\n",
    "iterations = 5000\n",
    "\n",
    "def calcRepresentation(learnRate, iterations, adMat, emMat, lossFunc):\n",
    "    tmpMat = emMat.copy()\n",
    "    i = 0\n",
    "    while i < iterations:\n",
    "        u = r.randint(1,cols)\n",
    "        v = r.randint(1,cols)\n",
    "        if u == v:\n",
    "            continue\n",
    "        \n",
    "        grad = lossFunc(u,v,tmpMat,adMat)\n",
    "        tmpMat = tmpMat - learnRate*grad\n",
    "        \n",
    "        i += 1\n",
    "    return tmpMat\n",
    "\n",
    "#1 and 2\n",
    "rep1 = calcRepresentation(learnRate, iterations, adMat, emMat, loss1)\n",
    "rep2 = calcRepresentation(learnRate, iterations, adMat, emMat, loss2)\n",
    "\n",
    "#print(rep1)\n",
    "#print(rep2)\n",
    "\n",
    "#get 5 most similar nodes to node 1 (0 doesnt exist yo)\n",
    "#returns list of tuples (distance, node nr)\n",
    "def findSimilarTo(emMat):\n",
    "    dist = []\n",
    "    leng = emMat.shape[0]\n",
    "    it = emMat.shape[1]\n",
    "    i = 1\n",
    "    while i < it:\n",
    "        j = 0\n",
    "        summ = 0\n",
    "        while j < leng:\n",
    "            summ += (emMat.item(0,j) - emMat.item(i,j))**2\n",
    "            j += 1\n",
    "        dist.append((math.sqrt(summ),i))\n",
    "        i += 1\n",
    "    return sorted(dist)[:5]\n",
    "\n",
    "#3\n",
    "print(findSimilarTo(rep1))\n",
    "print(findSimilarTo(rep2))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Should output:\n",
    "[(0.1374903330507991, 20), (0.16825999430199565, 18), (0.16825999430199567, 13), (0.17025130615174958, 16), (0.17316179571791193, 17)]\n",
    "[(0.13749033305079839, 20), (0.1682599943019948, 13), (0.1682599943019948, 18), (0.17025130615174897, 16), (0.173161795717911, 17)]"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nteract": {
   "version": "0.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
